هل تفضّل شرحًا «خطوة بخطوة» أم «نظرة شاملة» أولًا؟ سأقدّم أدناه خطة تنفيذ تفصيلية ومباشرة، موجهة لوكيل ترميز، تشمل الأوامر والعقود والملفات وخط الأنابيب كاملًا لتحويل الملف إلى تطبيق ويب تفاعلي باسم «المحطات»، مع تضمين إصلاحات S1/S2/S3 التي استنتجناها (إزالة التكرار، استبدال Pickle، فرض مخططات JSON، مهلات/إلغاء، وتطبيع العربية/RTL). 

# الأمر التوجيهي لوكيل الترميز — تحويل «stations.txt» إلى تطبيق ويب تفاعلي باسم «المحطات»

## 0) الهدف والنطاق

* الهدف: بناء تطبيق ويب تفاعلي (واجهة + خدمات خلفية) يُشغّل «محطات» التحليل S1/S2/S3 على نص سينمائي، ويعرض النتائج (الشخصيات، العلاقات، الأسلوب السردي، خرائط 3D، النغمة الديناميكية) بصيغ JSON وقوائم وجداول ورسوم شبكية.
* النطاق التنفيذي يشمل: إصلاحات الكود في S1/S2/S3، تعريف عقود بيانات صارمة، إنشاء واجهات API، واجهة React/Next.js، تشغيل موحّد، اختبارات، وحاويات.

---

## 1) المعمارية المستهدفة (Target Architecture)

* **المكدّس (Stack)**:

  * الواجهة الأمامية: Next.js 14 + TypeScript + React Query + React Flow (للشبكات) + Recharts (للرسوم).
  * الخدمات الخلفية: Python 3.11 + FastAPI + Uvicorn + Pydantic v2.
  * الربط: REST/JSON فقط (لا تبادل Pickle بين المحطات).
  * الحاويات: Docker + docker-compose (خدمة `web` و`api`).
  * التخزين: نظام ملفات المشروع `PROJECT_PATH` مع مجلد إخراج لكل محطة.
* **المبدأ المعماري**: فصل صارم بين الطبقات، وعقود JSON ثابتة بين الواجهة والخلفية، وتوحيد المسارات/التهيئة/التسجيل (logging).

> ملاحظة تنفيذية: شيفرات المحطات تستعمل متغيّرات بيئة مثل `PROSE_FILE_PATH`, `PROJECT_PATH`, `APP_CONFIG_PATH` ومسارات إخراج لكل محطة؛ وحاليًا تُخرِج أيضًا Pickle في S1/S2، وهذا سيُستبدل بـ JSON في القناة بين المحطات مع بقاء Pickle اختياريًا داخليًا فقط. 

---

## 2) هيكلة المستودع (Monorepo)

```
almohattat/
  apps/
    web/                 # Next.js (TS)
    api/                 # FastAPI (Python)
  packages/
    schemas/             # عقود Pydantic + مولّد Types TS
  data/
    projects/<project>/  # إخراج المحطات JSON (S1/S2/S3)
  docker/
    web.Dockerfile
    api.Dockerfile
  docker-compose.yml
  README.md
```

---

## 3) عقود البيانات (Contracts) — مُلزِمة

### 3.1 Pydantic (Python) — packages/schemas/py/s1.py

```python
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional

class CharacterAnalysis(BaseModel):
    Personality_Traits: Any = Field(default=None)
    Motivations_Goals: Any = Field(default=None)
    Key_Relationships_Brief: Any = Field(default=None)
    Narrative_Function: Any = Field(default=None)
    Potential_Arc_Observation: Any = Field(default=None)

class S1Outputs(BaseModel):
    full_text_snippet_s1: str
    major_characters_identified: Dict[str, List[str]] | Dict[str, Any]
    character_analysis: Dict[str, CharacterAnalysis] | Dict[str, Any]
    relationship_analysis: Dict[str, Any]
    narrative_style_analysis: Dict[str, Any]

class S1Payload(BaseModel):
    metadata: Dict[str, Any]
    analysis_outputs: S1Outputs
    performance_stats: Dict[str, Any]
```

### 3.2 S2/S3 (اختصارًا — على نفس النسق)

* S2: `conceptual_outputs.user_selections` يجب أن يحتوي:
  `final_story_statement`, `final_hybrid_genre`, `final_elevator_pitch`, `selected_3d_map_details`, `selected_dynamic_tone`, `selected_artistic_references`.
* S3: تمثيل شبكة الصراع (Characters, Relationships) بعقود صريحة للـ enum والقيم المسموح بها.

### 3.3 توليد Types للواجهة الأمامية

* أنشئ سكربت توليد Types من Pydantic إلى TS (مثل `pydantic2ts` أو مولّد بسيط):

```
pnpm dlx pydantic2ts packages/schemas/py --out apps/web/src/types/generated.d.ts
```

---

## 4) إصلاحات الكود الجوهرية في S1/S2/S3 (P0)

**نفّذ الآن، مع كومِت لكل بند:**

1. **إزالة تكرار تعريف `run_station1_prose_analysis` في S1**، والإبقاء على تعريف واحد ونقل الدوال المساعدة لأعلى الملف. الهدف: منع التباس الاستيراد/الدمج. 
2. **استبدال/تقييد Pickle**:

   * بين المحطات: JSON فقط وفق عقود الفقرة (3).
   * Pickle اختياري محلي «داخلي» عند الحاجة للأداء، مع تسمية واضحة وعدم تبادل خارج العملية. 
3. **فرض Schema**: عند تحضير `station1_dataset` ونتائج S2/S3، مرِّرها عبر نماذج Pydantic؛ الفشل يُرمى استثناءً وتُعاد استجابة HTTP 422. 
4. **مهلات/إلغاء/Backoff** لكل استدعاء AI متوازي في S1: لفّ `asyncio.create_task` بمهلة `asyncio.wait_for` وسياسة إعادة محاولات أسية (2–3 محاولات). 
5. **طبقة تطبيع عربية/RTL** قبل التحليل: NFC + إزالة التشكيل (اختياري) + تحويل الأرقام العربية/الفارسية إلى 0–9. اربطها قبل أي Regex/تحليل في S1. 
6. **توحيد مسارات I/O** في وحدة مسارات مشتركة، بدل الفروع المتعدّدة، مع متغيرات البيئة الثلاثة الموثقة. 

---

## 5) خدمة FastAPI (apps/api)

### 5.1 نقاط النهاية

* `POST /api/s1/run` — المدخل: `{ projectPath, proseFilePath, configPath? }`
  يُشغّل S1 ويعيد `S1Payload` كـ JSON.
* `POST /api/s2/run` — المدخل: مسارات S1 + النص (اختياري) → يعيد مخرجات S2 (user_selections + ai_suggestions الملخّصة).
* `POST /api/s3/run` — المدخل: مسارات S1/S2 → يعيد JSON لشبكة الصراع (عُقَد/حواف + meta).
* `GET /api/projects/:project/outputs` — قراءة ملخصات JSON للأقسام S1/S2/S3.

### 5.2 هيكل ملف رئيسي مختصر

```python
# apps/api/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio, os, json
from stations_adapter import run_s1, run_s2, run_s3

app = FastAPI(title="Almohattat API")

class RunS1Req(BaseModel):
    projectPath: str
    proseFilePath: str
    configPath: str | None = None

@app.post("/api/s1/run")
async def run_s1_ep(req: RunS1Req):
    try:
        result = await run_s1(req.projectPath, req.proseFilePath, req.configPath)
        return result # ← JSON مطابق للعقود
    except Exception as e:
        raise HTTPException(status_code=422, detail=str(e))
```

> ملاحظة: دالة `run_s1` تستورد وحدات S1 بعد إصلاحها وتُعيد كائن Pydantic `.model_dump()` بدل القواميس الحرّة.

---

## 6) الواجهة الأمامية (apps/web — Next.js)

### 6.1 الصفحات والمكوّنات

* `/` لوحة رئيسية: رفع ملف نص سيناريو + اختيار مشروع + تشغيل المحطات.
* `/projects/[name]` تبويب النتائج:

  * تبويب S1: قائمة الشخصيات الرئيسية، بطاقات تحليل شخصية، أسلوب سردي.
  * تبويب S2: بيان القصة، النوع الهجين، الملعب (Elevator Pitch)، خريطة 3D (جداول مرتبة).
  * تبويب S3: **رسم شبكة العلاقات** عبر React Flow؛ العقد = الشخصيات، الحواف = العلاقات (مع نوع/طبيعة/قوة/اتجاه).

### 6.2 استدعاء API (مثال)

```ts
// apps/web/src/lib/api.ts
export async function runS1(params: {projectPath:string; proseFilePath:string; configPath?:string}) {
  const r = await fetch("/api/s1/run", { method: "POST", headers: {"Content-Type":"application/json"}, body: JSON.stringify(params)});
  if (!r.ok) throw new Error(await r.text());
  return r.json(); // يطابق types المولَّدة
}
```

---

## 7) خطّ الأنابيب التنفيذي (Assemble → Grade → Mix → Render → Export)

### Assemble (تهيئة وبناء الهيكل)

* أوامر:

```bash
# جذع المستودع
git init && git add . && git commit -m "chore: repo init"

# Next.js
pnpm create next-app@latest apps/web --ts --eslint --app --src-dir --import-alias "@/*"
cd apps/web && pnpm add react-query reactflow recharts && cd -

# FastAPI
python -m venv .venv && . .venv/bin/activate
pip install fastapi uvicorn pydantic pytest
mkdir -p apps/api && touch apps/api/main.py
```

* DoD: يبنى مشروع الواجهة (`pnpm build`) وتعمل خدمة API محليًا (`uvicorn apps.api.main:app`).

### Grade (فرض الجودة والعقود)

* تنفيذ إصلاحات S1/S2/S3 (البند 4).
* إضافة اختبارات `pytest` لتمرير نماذج JSON عبر Pydantic.
* DoD: فشل صريح مع أي شكل غير مطابق؛ منع Pickle كقناة بين المحطات.

### Mix (الدمج)

* ربط صفحات الواجهة مع نقاط النهاية.
* تخزين نتائج المحطات تحت `data/projects/<name>/station{N}_output.json`.
* DoD: تشغيل S1→S2→S3 بالتسلسل من الواجهة الأمامية مع مؤشّر تقدم.

### Render (العرض)

* بناء رسوم الشبكة (React Flow) من JSON العلاقات (S3).
* جداول وخانات بحث/ترشيح للشخصيات/العلاقات.
* DoD: الشبكة تفاعلية (سحب/تكبير)، وتلوين الحواف بحسب الـ nature/strength.

### Export (التصدير)

* زر **تصدير تقرير**: ملف `.json` موحّد + PDF بسيط (خيار لاحق).
* DoD: تنزيل ملف ZIP يحوي JSON S1/S2/S3 ولقطة PNG للشبكة.

---

## 8) التهيئة والتشغيل

### متغيّرات البيئة

* `PROSE_FILE_PATH`, `PROJECT_PATH`, `APP_CONFIG_PATH` (تمريرها من واجهة Next إلى API ثم إلى S1/S2/S3). 
* مفاتيح مزوّدي النماذج (OpenAI/Google/OpenRouter/Together/Novita) وفق إعداداتك الحالية. 

### أوامر التطوير

```bash
# نافذة 1: API
. .venv/bin/activate
uvicorn apps.api.main:app --reload --port 8000

# نافذة 2: Web
cd apps/web
pnpm dev --port 3000
```

### Docker (اختياري)

* `docker-compose up --build` لتشغيل خدمتي `web` و`api`.

---

## 9) الأداء والموثوقية

* حد أقصى للتوازي في S1 عبر Semaphore=3 + `asyncio.wait_for(timeout=45)` + backoff أسّي 2 محاولات. 
* قياس زمن/ذاكرة عبر PerfTracker وتقارير موجزة على الواجهة. 
* تسجيل (logging) موحّد مستوى/تنسيق لكل محطة.

---

## 10) خطة الاختبار (Tests)

* **وحدة**: نماذج Pydantic، طبقة التطبيع العربية، محوّلات S1/S2/S3 إلى عقود JSON.
* **تكامل**: تشغيل S1→S2→S3 على ملف عينة عربي طويل؛ تحقق من وجود الحقول وقيَمها.
* **واجهة**: اختبار العرض والتفاعل للشبكة والعناصر.

---

## 11) المخاطر والتخفيف

* **تباين مخرجات النماذج**: Schema صارم + نسخ versioned للعقود.
* **انقطاعات واجهات AI**: مهلات/إعادة محاولات + رسائل واضحة للمستخدم.
* **نص عربي متنوع**: التطبيع قبل التحليل واختبارات متعددة.

---

## 12) معايير القبول (Acceptance / DoD)

* تشغيل «المحطات» محليًا: رفع نص → S1→S2→S3 → عرض النتائج دون أخطاء.
* عدم وجود Pickle كقناة تبادل بين المحطات؛ JSON فقط للعقود العامة.
* توفّر تصدير JSON موحّد، وشبكة علاقات تفاعلية.

---

## 13) أوامر تنفيذ مختصرة (للـ Agent)

نفّذ بالتسلسل، كل خطوة في كومِت منفصل:

1. **تهيئة المشروع**

```bash
git init && git add . && git commit -m "chore: init repo (almohattat)"
pnpm create next-app@latest apps/web --ts --eslint --app --src-dir --import-alias "@/*"
python -m venv .venv && . .venv/bin/activate && pip install fastapi uvicorn pydantic pytest
mkdir -p apps/api packages/schemas/py
```

2. **إصلاح S1/S2/S3**

* أزل التكرار في `run_station1_prose_analysis` بس1، وادمج التعريفَيْن.
* ألغِ Pickle كبروتوكول تبادل؛ أبقِ JSON فقط بين المحطات.
* مرّر كل المخرجات عبر Pydantic (سطرًا واحدًا قبل الحفظ/الإرجاع).
* أضِف طبقة `normalize_ar()` قبل التحليل.
* لفّ استدعاءات AI بمهلة وإعادة محاولة. 

3. **تعريف العقود ومولّد Types**

* ضع نماذج Pydantic في `packages/schemas/py` كما في الفقرة (3)، وولّد Types للويب.

4. **بناء API FastAPI**

```bash
uvicorn apps.api.main:app --reload --port 8000
```

5. **ربط الواجهة**

```bash
cd apps/web && pnpm add react-query reactflow recharts && pnpm dev
```

6. **تشغيل المسار الكامل**

* ارفع نصًا عربيًا، اضبط `projectName`، نفّذ S1→S2→S3 من الواجهة، راقب الشبكة والنتائج.

7. **الاختبارات والتصدير**

```bash
pytest -q
pnpm build
```

---
